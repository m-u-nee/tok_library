tokenizer_name_or_path: 'path/to/tokenizer'
eos_token: '<EOS>'
output_folder: 'path/to/output'
logging_dir: 'path/to/logs'
n_tasks: 8
n_workers: -1
shuffle: false
tokenizer_batch_size: 1000
reader: 'parquet'
dataset: 'path/to/dataset'
column: 'text'
split: 'train'
glob_pattern: '*.parquet'

slurm: false
partition: 'my_partition'
qos: 'normal'
time: '20:00:00'
email: 'example@example.com'
cpus_per_task: 1
mem_per_cpu_gb: 2